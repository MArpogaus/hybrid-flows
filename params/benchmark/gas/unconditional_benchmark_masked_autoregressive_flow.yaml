compile_kwargs:
  jit_compile: true
fit_kwargs:
  batch_size: 128
  early_stopping: 100
  epochs: 200
  learning_rate:
    scheduler_kwargs:
      decay_steps: 200
      end_learning_rate: 0.0001
      initial_learning_rate: 0.0005
      max_learning_rate: 0.01
      stationary: 20
      warmup: 5
      warmup_power: 1
    scheduler_name: polynomial_warmup_and_cosine_decay
  lr_patience:
  monitor: val_loss
  reduce_lr_on_plateau: false
  verbose: true
model_kwargs:
  distribution: masked_autoregressive_flow
  distribution_kwargs:
    allow_flexible_bounds: true
    bijector_name: bernstein_poly
    bounds: linear
    high: 1
    low: 0
    num_layers: 3
    order: 100
  parameter_kwargs:
    activation: tanh
    hidden_units:
    - 64
    - 64
