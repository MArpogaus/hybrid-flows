compile_kwargs:
  jit_compile: false
fit_kwargs:
  batch_size: 128
  early_stopping: 100
  epochs: 200
  learning_rate:
    # scheduler_kwargs:
    #   decay_steps: 200
    #   end_learning_rate: 0.0001
    #   initial_learning_rate: 0.0005
    #   max_learning_rate: 0.01
    #   stationary: 50
    #   warmup: 5
    #   warmup_power: 1
    # scheduler_name: polynomial_warmup_and_cosine_decay
    scheduler_kwargs:
      decay_steps: 200
      initial_learning_rate: 0.01
    scheduler_name: cosine_decay
  lr_patience:
  monitor: val_loss
  reduce_lr_on_plateau: false
  verbose: true
model_kwargs:
  distribution: masked_autoregressive_flow
  distribution_kwargs:
    allow_flexible_bounds: false
    bijector_name: bernstein_poly
    bounds: linear
    high: 4
    low: -4
    scale_to_domain: true
    num_layers: 8
    order: 32
  # parameter_fn: autoregressive_res_net
  parameter_kwargs:
    activation: sigmoid
    hidden_units:
    - 64
    - 64
