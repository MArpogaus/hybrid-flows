stages:
  train-sim:
    matrix:
      dataset: ${sim_datasets}
      model: ${sim_models}
    cmd: >-
      ${python} scripts/train.py
      --log-level ${log-level}
      --log-file train.log
      --model-name ${item.model}
      --stage-name train-sim@${key}
      --dataset-type ${item.dataset.type}
      --dataset-name ${item.dataset.name}
      --results-path results/
      --test-mode ${testmode}
      --experiment-name ${train-sim-experiment-name}
    params:
    - seed
    - textwidth
    - params/${item.dataset.type}/dataset.yaml:
      - dataset_kwargs.${item.dataset.name}*
    - params/${item.dataset.type}/${item.dataset.name}/${item.model}.yaml:
    deps:
    - scripts/train.py
    - ../pyproject.toml
    - ../src/hybrid_flows/data/__init__.py
    - ../src/hybrid_flows/data/sklearn_datasets.py
    - ../src/hybrid_flows/utils/__init__.py
    - ../src/hybrid_flows/utils/mlflow.py
    - ../src/hybrid_flows/utils/tensorflow.py
    - ../src/hybrid_flows/utils/visualisation.py
    - ../src/hybrid_flows/utils/decorators.py
    - ../src/hybrid_flows/utils/pipeline.py
    - ../src/hybrid_flows/__init__.py
    - ../src/hybrid_flows/preprocessing.py
    - ../src/hybrid_flows/scheduler.py
    - ../src/hybrid_flows/activations.py
    - ../src/hybrid_flows/models.py
    - ../src/hybrid_flows/nn.py
    - ../src/hybrid_flows/parameters.py
    - ../src/hybrid_flows/distributions.py
    metrics:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/metrics.yaml
    outs:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/model_checkpoint.weights.h5
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/train.log
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/dataset.pdf
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/samples.pdf

  eval-sim:
    matrix:
      dataset: ${sim_datasets}
      model: ${sim_models}
    cmd: >-
      ${python} scripts/evaluate_sim.py
      --log-level ${log-level}
      --log-file evaluate.log
      --model-name ${item.model}
      --stage-name eval-sim@${key}
      --dataset-type ${item.dataset.type}
      --dataset-name ${item.dataset.name}
      --results-path results/
      --experiment-name ${eval-sim-experiment-name}
    params:
    - seed
    - textwidth
    - testmode
    - params/${item.dataset.type}/dataset.yaml:
      - dataset_kwargs.${item.dataset.name}*
    - params/${item.dataset.type}/${item.dataset.name}/${item.model}.yaml:
    deps:
    - scripts/train.py
    - scripts/evaluate_sim.py
    - ../pyproject.toml
    - ../src/hybrid_flows/data/__init__.py
    - ../src/hybrid_flows/data/sklearn_datasets.py
    - ../src/hybrid_flows/utils/__init__.py
    - ../src/hybrid_flows/utils/mlflow.py
    - ../src/hybrid_flows/utils/tensorflow.py
    - ../src/hybrid_flows/utils/visualisation.py
    - ../src/hybrid_flows/utils/decorators.py
    - ../src/hybrid_flows/utils/pipeline.py
    - ../src/hybrid_flows/__init__.py
    - ../src/hybrid_flows/preprocessing.py
    - ../src/hybrid_flows/scheduler.py
    - ../src/hybrid_flows/activations.py
    - ../src/hybrid_flows/models.py
    - ../src/hybrid_flows/nn.py
    - ../src/hybrid_flows/parameters.py
    - ../src/hybrid_flows/distributions.py
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/model_checkpoint.weights.h5
    outs:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/eval_figures/
    metrics:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/evaluation_metrics.yaml

  train-benchmark:
    matrix:
      dataset: ${benchmark_datasets}
      model: ${benchmark_models}
    cmd: >-
      ${python} scripts/train.py
      --log-level ${log-level}
      --log-file train.log
      --model-name ${item.model}
      --stage-name train-benchmark@${key}
      --dataset-type ${item.dataset.type}
      --dataset-name ${item.dataset.name}
      --results-path results/
      --test-mode ${testmode}
      --experiment-name ${train-benchmark-experiment-name}
    params:
    - log-level
    - seed
    - textwidth
    - params/${item.dataset.type}/dataset.yaml:
      - dataset_kwargs.${item.dataset.name}*
    - params/${item.dataset.type}/${item.dataset.name}/${item.model}.yaml:
    deps:
    - scripts/train.py
    - ../pyproject.toml
    - ../src/hybrid_flows/data/__init__.py
    - ../src/hybrid_flows/data/benchmark.py
    - ../src/hybrid_flows/utils/__init__.py
    - ../src/hybrid_flows/utils/mlflow.py
    - ../src/hybrid_flows/utils/tensorflow.py
    - ../src/hybrid_flows/utils/visualisation.py
    - ../src/hybrid_flows/utils/decorators.py
    - ../src/hybrid_flows/utils/pipeline.py
    - ../src/hybrid_flows/__init__.py
    - ../src/hybrid_flows/preprocessing.py
    - ../src/hybrid_flows/scheduler.py
    - ../src/hybrid_flows/activations.py
    - ../src/hybrid_flows/models.py
    - ../src/hybrid_flows/nn.py
    - ../src/hybrid_flows/parameters.py
    - ../src/hybrid_flows/distributions.py
    - datasets/${item.dataset.type}/${item.dataset.name}_train.npy
    - datasets/${item.dataset.type}/${item.dataset.name}_validate.npy
    metrics:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/metrics.yaml
    outs:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/model_checkpoint.weights.h5
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/train.log

  eval-benchmark:
    matrix:
      dataset: ${benchmark_datasets}
      model: ${benchmark_models}
    cmd: >-
      ${python} scripts/evaluate_benchmark.py
      --log-level ${log-level}
      --log-file evaluate.log
      --model-name ${item.model}
      --stage-name eval-benchmark@${key}
      --dataset-type benchmark
      --dataset-type ${item.dataset.type}
      --dataset-name ${item.dataset.name}
      --results-path results/
      --experiment-name ${eval-benchmark-experiment-name}
    params:
    - log-level
    - seed
    - textwidth
    - params/${item.dataset.type}/dataset.yaml:
      - dataset_kwargs.${item.dataset.name}*
    - params/${item.dataset.type}/${item.dataset.name}/${item.model}.yaml:
    deps:
    - scripts/train.py
    - scripts/evaluate_benchmark.py
    - ../pyproject.toml
    - ../src/hybrid_flows/data/__init__.py
    - ../src/hybrid_flows/data/benchmark.py
    - ../src/hybrid_flows/utils/__init__.py
    - ../src/hybrid_flows/utils/mlflow.py
    - ../src/hybrid_flows/utils/tensorflow.py
    - ../src/hybrid_flows/utils/visualisation.py
    - ../src/hybrid_flows/utils/decorators.py
    - ../src/hybrid_flows/utils/pipeline.py
    - ../src/hybrid_flows/__init__.py
    - ../src/hybrid_flows/preprocessing.py
    - ../src/hybrid_flows/scheduler.py
    - ../src/hybrid_flows/activations.py
    - ../src/hybrid_flows/models.py
    - ../src/hybrid_flows/nn.py
    - ../src/hybrid_flows/parameters.py
    - ../src/hybrid_flows/distributions.py
    - datasets/${item.dataset.type}/${item.dataset.name}_train.npy
    - datasets/${item.dataset.type}/${item.dataset.name}_validate.npy
    - datasets/${item.dataset.type}/${item.dataset.name}_test.npy
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/model_checkpoint.weights.h5
    outs:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/eval_figures/
    metrics:
    - results/${item.dataset.type}/${item.dataset.name}/${item.model}/evaluation_metrics.yaml

  train-malnutrition:
    foreach: ${malnutrition_models}
    do:
      cmd: >-
        ${python} scripts/train.py
        --log-level ${log-level}
        --log-file train.log
        --model-name ${item}
        --stage-name train-malnutrition@${item}
        --dataset-type malnutrition
        --dataset-name india
        --results-path results/
        --test-mode ${testmode}
        --experiment-name ${train-malnutrition-experiment-name}
      params:
      - seed
      - textwidth
      - params/malnutrition/dataset.yaml:
        - dataset_kwargs.india*
      - params/malnutrition/${item}.yaml:
      deps:
      - scripts/train.py
      - ../pyproject.toml
      - ../src/hybrid_flows/data/__init__.py
      - ../src/hybrid_flows/data/malnutrion.py
      - ../src/hybrid_flows/utils/__init__.py
      - ../src/hybrid_flows/utils/mlflow.py
      - ../src/hybrid_flows/utils/tensorflow.py
      - ../src/hybrid_flows/utils/visualisation.py
      - ../src/hybrid_flows/utils/decorators.py
      - ../src/hybrid_flows/utils/pipeline.py
      - ../src/hybrid_flows/__init__.py
      - ../src/hybrid_flows/preprocessing.py
      - ../src/hybrid_flows/scheduler.py
      - ../src/hybrid_flows/activations.py
      - ../src/hybrid_flows/models.py
      - ../src/hybrid_flows/nn.py
      - ../src/hybrid_flows/parameters.py
      - ../src/hybrid_flows/distributions.py
      metrics:
      - results/malnutrition/india/${item}/metrics.yaml
      outs:
      - results/malnutrition/india/${item}/model_checkpoint.weights.h5
      - results/malnutrition/india/${item}/train.log
      - results/malnutrition/india/${item}/dataset.pdf
      - results/malnutrition/india/${item}/samples.pdf

  eval-malnutrition:
    foreach: ${malnutrition_models}
    do:
      cmd: >-
        ${python} scripts/evaluate_malnutrition.py
        --log-level ${log-level}
        --log-file evaluate.log
        --model-name ${item}
        --stage-name eval-malnutrition@${item}
        --dataset-type malnutrition
        --dataset-name india
        --results-path results/
        --experiment-name ${eval-malnutrition-experiment-name}
      params:
      - seed
      - textwidth
      - params/malnutrition/dataset.yaml:
        - dataset_kwargs.india*
      - params/malnutrition/${item}.yaml:
      deps:
      - scripts/evaluate_malnutrition.py
      - results/malnutrition/india/${item}/model_checkpoint.weights.h5
      outs:
      - results/malnutrition/india/${item}/eval_figures/
