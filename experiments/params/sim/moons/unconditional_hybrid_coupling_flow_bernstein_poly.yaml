compile_kwargs:
  jit_compile: false
two_stage_training: true
fit_kwargs:
- epochs: 1000
  batch_size: 1024
  learning_rate: 0.05
  reduce_lr_on_plateau: false
  early_stopping: 50
  monitor: val_loss
  verbose: true
  validation_split: 0.25
- epochs: 400
  batch_size: 512
  learning_rate:
    scheduler_kwargs:
      decay_steps: epochs
      initial_learning_rate: 0.001
    scheduler_name: cosine_decay
  reduce_lr_on_plateau: false
  early_stopping: 50
  monitor: val_loss
  verbose: true
  validation_split: 0.25
model_kwargs:
  marginal_bijectors:
  - bijector: BernsteinPolynomial
    invert: true
    bijector_kwargs:
      domain: [0, 1]
      extrapolation: false
    parameters_constraint_fn: mctm.activations.get_thetas_constrain_fn
    parameters_constraint_fn_kwargs:
      allow_flexible_bounds: false
      bounds: linear
      high: 5
      low: -5
    parameters_fn: parameter_vector
    parameters_fn_kwargs:
      dtype: float32
      parameter_shape: [&dims 2, 300]
  joint_bijectors:
  - bijector: RealNVP
    bijector_kwargs:
      num_masked: 1
    nested_bijector:
      bijector: BernsteinPolynomial
      invert: true
      bijector_kwargs:
        domain: [-5, 5]
        extrapolation: false
      parameters_constraint_fn: mctm.activations.get_thetas_constrain_fn
      parameters_constraint_fn_kwargs:
        allow_flexible_bounds: false
        bounds: linear
        high: 5
        low: -5
      parametrized_by_parent: true
    parameters_fn: fully_connected_network
    parameters_fn_kwargs:
      activation: relu
      batch_norm: false
      dropout: false
      hidden_units:
      - 512
      - 128
      - 1024
      dtype: float32
      input_shape: [1]
      parameter_shape: [1, 2000]
