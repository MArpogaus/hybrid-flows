compile_kwargs:
  jit_compile: true
two_stage_training: true
fit_kwargs:
- epochs: 400
  batch_size: 512
  learning_rate: 0.01
  reduce_lr_on_plateau: false
  early_stopping: 50
  monitor: val_loss
  verbose: true
  validation_split: 0.25
- epochs: 400
  batch_size: 512
  learning_rate:
    scheduler_kwargs:
      decay_steps: 400
      initial_learning_rate: 0.01
    scheduler_name: cosine_decay
  reduce_lr_on_plateau: false
  early_stopping: 50
  monitor: val_loss
  verbose: true
  validation_split: 0.25
model_kwargs:
  marginal_bijectors:
  - bijector: BernsteinPolynomial
    invert: true
    bijector_kwargs:
      domain: [0, 1]
      extrapolation: false
    parameters_constraint_fn: mctm.activations.get_thetas_constrain_fn
    parameters_constraint_fn_kwargs:
      allow_flexible_bounds: true
      bounds: linear
      high: 5
      low: -5
    parameters_fn: parameter_vector
    parameters_fn_kwargs:
      dtype: float32
      parameter_shape: [&dims 2, 300]
  - bijector: Shift
    invert: true
    parameters_fn: bernstein_polynomial
    parameters_fn_kwargs:
      conditional_event_shape: 1
      dtype: float
      extrapolation: true
      parameter_shape: [*dims]
      polynomial_order: 6
  joint_bijectors:
  - bijector: RealNVP
    bijector_kwargs:
      num_masked: 1
    nested_bijector:
      bijector: BernsteinPolynomial
      invert: true
      bijector_kwargs:
        domain: [-8, 8]
        extrapolation: false
      parameters_constraint_fn: mctm.activations.get_thetas_constrain_fn
      parameters_constraint_fn_kwargs:
        allow_flexible_bounds: true
        bounds: linear
        high: 5
        low: -5
      parametrized_by_parent: true
    # parameters_fn: bernstein_polynomial
    # parameters_fn_kwargs:
    #   conditional_event_shape: 1
    #   dtype: float
    #   extrapolation: true
    #   parameter_shape: [1, 100]
    #   polynomial_order: 300
    #   conditional: false
    #   domain: [-5, 5]
    parameters_fn: fully_connected_network
    parameters_fn_kwargs:
      activation: relu
      batch_norm: false
      dropout: false
      hidden_units:
      - 512
      - 512
      - 512
      dtype: float32
      input_shape: [1]
      parameter_shape: [1, 512]
      conditional: true
      conditional_event_shape: 1
