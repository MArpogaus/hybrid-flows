compile_kwargs: {}
  # jit_compile: true
two_stage_training: true
fit_kwargs:
  epochs: &epochs 100
  batch_size: 128
  learning_rate:
    scheduler_kwargs:
      decay_steps: *epochs
      initial_learning_rate: 0.005
    scheduler_name: cosine_decay
  reduce_lr_on_plateau: false
  early_stopping: false
  monitor: val_loss
  verbose: true
model_kwargs:
  marginal_bijectors:
  - bijector: BernsteinPolynomial
    invert: true
    bijector_kwargs:
      domain: [-5, 5]
      extrapolation: true
    parameters_constraint_fn: mctm.activations.get_thetas_constrain_fn
    parameters_constraint_fn_kwargs:
      allow_flexible_bounds: false
      bounds: linear
      high: 5
      low: -5
    parameters_fn: parameter_vector
    parameters_fn_kwargs:
      dtype: float32
      parameter_shape: [&dims 3, 6]
  - bijector: Shift
    invert: true
    parameters_fn: bernstein_polynomial
    parameters_fn_kwargs:
      conditional_event_shape: 1
      domain: [0, 35]
      dtype: float
      extrapolation: true
      parameter_shape: [*dims]
      polynomial_order: 6
  joint_flow_type: masked_autoregressive_flow_first_dim_masked
  joint_bijectors:
    num_layers: 1
    num_parameters: 47 # 16 * 3 - 1
    bijector: RationalQuadraticSpline
    bijector_kwargs:
      range_min: -6
    parameters_constraint_fn_kwargs:
      interval_width: 12
      min_slope: 0.001
      min_bin_width: 0.001
      nbins: 32
    # invert: True
    maf_parameters_fn_kwargs:
      activation: relu
      hidden_units:
      - 512
      - 512
      - 512
      dtype: float32
      conditional: true
      conditional_event_shape: 1
    x0_parameters_fn_kwargs:
      activation: relu
      batch_norm: false
      dropout: false
      hidden_units:
      - 512
      - 512
      - 512
      dtype: float32
      conditional: true
      conditional_event_shape: 1
